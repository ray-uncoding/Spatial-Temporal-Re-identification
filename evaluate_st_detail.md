# evaluate_st.py 詳細流程說明

本檔案負責評估模型在測試集上的表現，將外觀特徵與時空分布結合，計算查詢（query）與資料庫（gallery）圖片的最終相似度分數，並輸出 Rank-1、mAP 等指標。

## 主要流程

1. **參數設定與資料載入**
   - 透過 argparse 讀取模型名稱、融合參數 alpha、時空分布平滑參數 smooth。
   - 載入 query 與 gallery 的特徵、標籤、攝影機編號、影格等資料。
   - 載入時空分布模型（distribution）。

2. **特徵正規化**
   - 將 query 與 gallery 的特徵向量做 L2 normalization，確保特徵長度一致。

3. **時空分布平滑**
   - 對時空分布進行高斯平滑（gauss_smooth2），避免分布過於稀疏。
   - 再對每個分布做歸一化，確保為機率分布。

4. **查詢與資料庫比對**
   - 對每個 query，計算其與所有 gallery 的：
     - 外觀分數（特徵點積）
     - 時空分數（根據攝影機與時間差查表）
   - 兩種分數融合：
     `score = 1/(1+exp(-alpha*score_appearance)) * 1/(1+2*exp(-alpha*score_st))`

5. **排序與評估**
   - 根據最終分數降序排序，計算 CMC（累積匹配特徵曲線）、mAP（mean Average Precision）。
   - 排除同攝影機或無效樣本（good/junk index 設計）。

6. **結果輸出**
   - 輸出 top1、top5、top10、mAP 等指標。
   - 儲存 CMC 結果至 .mat 檔案。

---

# gen_st_model_market.py / gen_st_model_duke.py 詳細流程說明

這兩個檔案負責根據訓練集資料，統計不同攝影機間的時間差分布，建立時空分布模型。

## 主要流程

1. **資料解析**
   - 解析每張圖片的 ID、攝影機編號、影格時間（根據檔名格式）。

2. **統計每個 ID 在每個攝影機的平均時間**
   - 對每個 ID、每個攝影機，累加影格時間並計算平均值。

3. **建立時間差分布**
   - 對每個 ID，兩兩攝影機組合，計算平均時間差，分箱（以 100 為單位）累加到分布矩陣。
   - 分布矩陣 shape 為 (8,8,max_hist)，代表 8 個攝影機間的時間差分布。

4. **分布正規化**
   - 對每個攝影機組合的分布做歸一化，確保為機率分布。

5. **結果輸出**
   - 將分布儲存為 .mat 檔案，供評估用。

---

這些檔案共同實現了「空間-時間人物再識別」的評估核心：不僅考慮外觀特徵，還結合了跨攝影機的時空資訊，提升跨攝影機人物識別的準確率。
